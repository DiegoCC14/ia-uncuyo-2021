<h1> TP1 Fundamentos de la IA - LCC 2021 </h1>

###Diego Rinaldo Cazon Condori
	

Los filosófos existían mucho antes que los computadores y llevaban tiempo intentando solucionar algunas cuestiones relacionadas con la
IA: ¿cómo trabaja la mente? ¿Es posible que las máquinas actúen de forma inteligente,igual que las personas? Y si así fuera, ¿tendrían mentes? ¿Cuáles son las implicaciones éticas de las máquinas inteligentes?.
	Los filósofos definen la hipótesis de la IA débil como la afirmación de que es posible que las máquinas actúen con inteligencia de la misma manera, la hipótesis de la IA fuerte consiste en la afirmación de que las máquinas sí piensan realmente. La mayoría de los investigadores de IA dan por sentado la hipótesis de la IA débil, y no se preocupan por la hipótesis de la IA fuerte, con tal de que funcione su programa no les interesa si se llama simulación de inteligencia o inteligencia real. Sin embargo, todos deberían preocuparse por las implicaciones éticas de su trabajo.

IA débil: ¿pueden las máquinas actuar con inteligencia?

	Obviamente, si la IA es imposible o no lo es, dependerá de cómo se defina. En esencia, la IA consiste en la búsqueda del mejor programa agente en una arquitectura dada. Con esta formulación, la IA es posible. Nuestra definición de IA funciona bien para el problema de encontrar un buen agente, dependiendo de la arquitectura. Sin
embargo, los filósofos están interesados en el problema de comparar dos arquitecturas,
la humana y la de la máquina. Además, ellos por tradición han formulado la pregunta
de la siguiente manera: ¿Pueden pensar las máquinas? ̈ Desgraciadamente, esta
cuestión no está bien definida. Para ver por qué, consideremos las dos cuestiones si-
guientes:
• ¿Pueden volar las máquinas?
• ¿Pueden nadar las máquinas?
La mayoría de las personas están de acuerdo en que la respuesta a la primera cuestión
es sí, que los aviones pueden volar, pero la respuesta a la segunda es no; los barcos y los submarinos se mueven por el agua, pero eso no es nadar. Sin embargo, ni las preguntas ni sus respuestas afectan en absoluto a las vidas laborales de los ingenieros aeronáuticos ni navales. Las respuestas no tienen mucho que ver con el diseño o con las características de los aviones o de los submarinos,  y sin embargo sí tienen que ver mucho más con la forma en que se han elegido utilizar
las palabras. La posibilidad práctica de las “máquinas pensantes” lleva viviendo con nosotros durante sólo 50 años o así, tiempo insuficiente para que los angloparlantes se decidan a dar un significado a la palabra “pensar“.
Alan Turing, en su famoso artículo, sugirió que en vez de preguntar si las máquinas pueden pensar, deberíamos preguntar si las máquinas pueden aprobar un test de de comportamiento, conocido como el Test de Turing. La prueba se realiza para que el programa mantenga una conversación durante cinco minutos (mediante mensajes escritos) con un interrogador. Éste tiene que averiguar si la conversación se
está llevando a cabo con un programa o con una persona, si el programa engaña al
interlocutor un 30 por ciento del tiempo, este pasará la prueba. Algunas personas han sido engañadas durante cinco minutos, por ejemplo, el programa ALICE engañó a un juez en la competición del Loebner Prize en el año 2001. Sin embargo, nin-
gún programa se ha acercado al criterio del 30 por ciento frente a jueces con conocimiento, y el campo de la IA no ha prestado mucha atención a los tests de Turing. 


IA fuerte: ¿pueden las máquinas pensar 
de verdad? 
Muchos filósofos han afirmado que una máquina que pasa el Test de Turing no quiere
decir que esté realmente pensando, sería solamente una simulación de la acción de 
pensar. 
La respuesta de Turing a esta objeción es interesante.Turing mantiene que la cuestión no está bien definida al decir, ¿Pueden pensar las máquinas? Además, por qué deberíamos insistir en un estándar más alto para las máquinas que el usado para los humanos. Después de todo, en la vida ordinaria no tenemos nunca una evidencia directa sobre los estados mentales internos de otras personas.
	Turing reconoce que la cuestión de la conciencia es difícil, pero niega que
sea relevante para la práctica de la IA. Coincidimos con Turing en que nos interesa crear programas que se comporten de forma inteligente y no en si alguien los declara reales o simulados.

	Podemos concluir diciendo que en algunos casos el comportamiento de un artefacto es importante, aunque en otros sea el pedigrí del artefacto lo que importa. Lo importante en cada caso parece ser una cuestión de convención. Sin embargo para las mentes artificiales, no existe una convención, y tenemos que depender de las intuiciones. 

La ética y los riesgos de desarrollar 
la Inteligencia Artificial 


	Hasta ahora nos hemos concentrado en si podemos desarrollar la IA, pero debemos también tener en cuenta si deberíamos hacerlo. Si es más probable que los efectos de la tecnología de la IA sean más negativos que positivos, sería responsabilidad moral de los trabajadores en su campo redirigir su investigación. Muchas de las nuevas tecnologías han tenido efectos negativos no intencionados , la fisión nuclear produjo el desastre de Chernobyl, la Isla de las Tres Millas y la amenaza de la destrucción mundial. Existe incluso un manual sobre la Ética de los Computadores. Sin embargo, La IA parece que expone problemas nuevos.

	Las personas podrían perder sus trabajos por la automatización. La economía
industrial moderna ha llegado a depender en general de los computadores, y selecciona programas de IA en particular. La automatización por medio de la tecnología de la IA ha creado más trabajos de los que ha eliminado, y ha creado puestos de trabajo más interesantes y mejor pagados. Ahora que el programa IA canónico es un agente inteligente diseñado para ayudar a un hombre, la pérdida de trabajo preocupa menos que cuando la IA se centraba en los sistemas expertos diseñados para sustituir a los hombres.

Las personas podrían tener demasiado (o muy poco) tiempo de ocio. Alvin Toffler
en su libro Future Shock (1970) escribió, «La semana laboral se ha recortado el 50 por
ciento a finales del siglo. No es absurdo decir que se volverá a reducir a la mitad hacia el año 2000 ̈. Arthur C. Clarke (1968b) escribió que las personas del año 2001 «podrían en frentarse a un futuro de gran aburrimiento, en donde el problema principal de la vida es decidir cual de los cientos de canales de la televisión seleccionar ̈. La única predicción que ha llegado a resultar cierta es el número de canales de televisión . En cambio, las personas que trabajan en las industrias muy relacionadas con el conocimiento han descubierto que forman parte de un sistema computerizado integrado que funciona 24 horas al día; para mantenerlo se han visto forzados a trabajar durante más horas. La IA  incrementa el ritmo de la innovación tecnológica y contribuye así a esta tendencia general, pero la IA también mantiene la promesa de permitirnos ahorrar tiempo y permitir que nuestros agentes automatizados hagan las cosas por un tiempo.

Las personas podrían perder algo de sus derechos privados. Weizenbaum también
señaló que la tecnología del reconocimiento de voz podría llevar a una intercepción
extensa de cableados, y de aquí a la pérdida de las libertades civiles. No previó un mundo con amenazas terroristas que cambiarían el equilibrio de la vigilancia que estarían dispuestas a aceptar las personas, sino que reconocería correctamente que la IA tiene el Potencial de producir una vigilancia en grandes cantidades. Esta predicción puede convertirse en realidad: el sistema clasificado Echelon del gobierno americano consiste en Una red de envíos de escucha, campos de antenas y estaciones de radar; el sistema está respaldado por computadores que utilizan traducción de lenguajes, reconocimiento de voz y palabras clave que buscan pasar por la criba automáticamente todo el tráfico de llamadas telefónicas, correos electrónicos, faxes . Algunas personas reconocen que la computerización conduce a la pérdida de privacidad. La utilización de sistemas de IA podría llevar a la pérdida de responsabilidad. En
la atmósfera de litigios que prevalece en Estados Unidos, la obligación legal se convierte en un tema importante. Cuando un médico depende del juicio de un sistema médico experto para hacer diagnóstico, ¿quién es el culpable si el diagnóstico es erróneo? Afortunadamente, debido en parte a la mayor influencia en medicina de métodos teóricos para las decisiones, se acepta que la negligencia no puede demostrarse si un médico lleva cabo procedimientos médicos que tienen una utilidad altamente esperada, incluso si el resultado real es catastrófico para el paciente. Por tanto la pregunta debería ser ¿Quién tiene la culpa si el diagnóstico no es razonable? . Hasta ahora, los juzgados han mantenido que los sistemas médicos expertos desempeñan el mismo papel que los libros de
texto médicos y los libros de referencias; los médicos son responsables de entender el
razonamiento que soporta esta decisión y de utilizar su propio juicio a la ahora de decidir si se aceptan las recomendaciones del sistema. Por tanto, en el diseño de sistemas médicos expertos como agentes, no se debería considerar que las acciones afectan directamente a los pacientes, sino que influyen directamente en el comportamiento del médico. Si los sistemas expertos se hacen más fiables y precisos que los hombres que hacen los diagnósticos, los médicos podrían tener obligaciones legales si no utilizan las recomendaciones de un sistema experto.
Están empezando a aparecer temas similares en relación con la utilización de agen-
tes inteligentes en Internet. Si las transacciones monetarias las realiza un agente inteligente en nombre de alguien, ¿está obligado por las deudas incurridas? ¿Sería posible que un agente inteligente tuviera activos o que realizara compras electrónicas en su propio nombre? Hasta ahora, parece que estas cuestiones no se entienden de forma clara.Al igual que con la tecnología para la reproducción humana, la ley tiene todavía que ponerse a la altura de los nuevos desarrollos.

El éxito de la IA podría significar el fin de la raza humana. Casi cualquier tecnolo-
gía tiene el potencial de hacer daño si se encuentra en las manos equivocadas, pero con la IA y la robótica, tenemos el problema nuevo de que las manos equivocadas podrían pertenecer a dicha tecnología.
Para una gran mayoría, parece que los robots son protagonistas de muchas historias
de conquistas del mundo porque representan lo desconocido, de la misma manera que
las brujas y los fantasmas de cuentos de otras décadas más antiguas. Si los robots estuvieran diseñados adecuadamente como agentes que adoptan las metas de sus propietarios, probablemente no supondrían una amenaza. Los hombres utilizan su inteligencia de formas agresivas porque son innatas, por naturaleza. Sin embargo, las máquinas que construimos no tienen que seragresivas, a menos que decidamos que así sean. Por un lado, es posible que los computadores logren una clase de conquista sirviendo y haciéndose indispensables, de la misma manera que los automóviles han conquistado en cierto sentido el mundo industrializado.

Finalmente, tomemos en consideración el punto de vista del robot. Si los robots
adquieren consciencia, tratarlos entonces como meras máquinas podría ser inmoral. Los robots también deben actuar moralmente, 
necesitaríamos programarlos con una teoría de lo que está bien y lo que está mal.
